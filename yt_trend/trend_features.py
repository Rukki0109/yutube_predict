#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
trend_features.py
-----------------
æ€¥ä¸Šæ˜‡ï¼ˆTrendingï¼‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ CSV ç¾¤ã‹ã‚‰ã€Œä»Šã®æµè¡Œèªã€è¾æ›¸ã‚’ä½œã‚Šã€
ä»»æ„ã®ã‚¿ã‚¤ãƒˆãƒ«æ–‡å­—åˆ—ã«å¯¾ã—ã¦ä»¥ä¸‹ã®ç‰¹å¾´é‡ã‚’è¿”ã—ã¾ã™:

- trend_overlap_count: æµè¡Œèªã¨ã®ä¸€è‡´èªæ•°
- trend_overlap_ratio: ãã®ã‚¿ã‚¤ãƒˆãƒ«ã®å½¢æ…‹ç´ æ•°ã«å¯¾ã™ã‚‹ä¸€è‡´æ¯”
- trend_cosine_sim:    æ€¥ä¸Šæ˜‡ã‚¿ã‚¤ãƒˆãƒ«é›†åˆã¨ã® Bag-of-Words ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦

ä½¿ã„æ–¹ï¼ˆä¾‹ï¼‰:
  python trend_features.py --trending_csvs trending_JP_20250925.csv trending_JP_20250926.csv --title "é˜¿ä¿®ç¾…ãƒ¢ãƒ¼ãƒ‰çªå…¥ï¼ã‚¬ãƒå–§å˜©ã§çµ¶å¥ã®ç¬é–“"

å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆæ–¹é‡:
1) æ—¥æ¬¡ã§ get_trending.py ã‚’å®Ÿè¡Œã—ã¦ CSV ã‚’è²¯ã‚ã‚‹
2) ç›´è¿‘Næ—¥ï¼ˆä¾‹: 7æ—¥ or 14æ—¥ï¼‰ã® CSV ã‚’èª­ã¿è¾¼ã¿ã€ã€Œtrend_vocab.jsonã€ã‚’ç”Ÿæˆ
3) feature_extraction.py å†…ã§å„ã‚µãƒ³ãƒ—ãƒ«ã®ã‚¿ã‚¤ãƒˆãƒ«â†’ trendç‰¹å¾´é‡ã‚’è¨ˆç®—ã—ã¦åˆ—ã‚’è¿½åŠ 
4) äºˆæ¸¬æ™‚ï¼ˆpredict_view_count.pyï¼‰ã§ã‚‚åŒã˜ trend_vocab.json ã‚’ä½¿ã£ã¦ç‰¹å¾´é‡ã‚’è¿½åŠ 
"""
import argparse
import json
import os
import re
from collections import Counter
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- è¶…è»½é‡ãªæ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ï¼ˆã‚¹ãƒšãƒ¼ã‚¹/è¨˜å·ã§åˆ†å‰²ï¼‰---
# ç²¾å¯†ã«ã¯ Janome / Sudachi ã‚’æ¨å¥¨ã€‚æ—¢å­˜ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ Janome ã‚’ä½¿ã£ã¦ã„ã‚Œã°å·®ã—æ›¿ãˆå¯èƒ½ã€‚
TOKEN_PATTERN = re.compile(r"[^\wã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯]+")

def tokenize(text: str):
    text = text.lower().strip()
    text = TOKEN_PATTERN.sub(" ", text)
    toks = [t for t in text.split() if t]
    return toks

def build_trend_vocab_from_csvs(csv_paths, top_k: int=500):
    """
    è¤‡æ•°æ—¥ã® trending CSV ã‚’èª­ã¿ã€ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰å‡ºç¾é »åº¦ã®é«˜ã„èªã‚’ top_k æŠœãå‡ºã™ã€‚
    è¿”ã‚Šå€¤:
      - hotwords: list[str] ä¸Šä½å˜èªï¼ˆé‡è¤‡é™¤å»ï¼‰
      - titles: list[str]  å…¨ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆBoWç”¨ï¼‰
    """
    titles = []
    for p in csv_paths:
        if not os.path.exists(p):
            continue
        df = pd.read_csv(p)
        titles.extend(df["title"].fillna("").tolist())
    # å˜èªé »åº¦
    cnt = Counter()
    for t in titles:
        cnt.update(tokenize(t))
    # æ¥µç«¯ã«çŸ­ã„/ä¸€èˆ¬èªã‚’é›‘ã«é™¤å¤–ï¼ˆèª¿æ•´å¯èƒ½ï¼‰
    stop = set(["ã®","ã«","ã‚’","ãŒ","ã§","ã¨","ã¯","ã‚‚","ã‚„","ww","www","w","the","and","for","a","to","in"])
    hotwords = [w for w,_c in cnt.most_common(top_k*2) if (len(w) >= 2 and w not in stop)]
    hotwords = hotwords[:top_k]
    return hotwords, titles

def save_trend_vocab_json(hotwords, json_path="trend_vocab.json"):
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump({"hotwords": hotwords}, f, ensure_ascii=False, indent=2)
    return json_path

def load_trend_vocab_json(json_path="trend_vocab.json"):
    with open(json_path, "r", encoding="utf-8") as f:
        return json.load(f)["hotwords"]

def title_trend_features(title: str, hotwords, trend_titles_for_bow=None):
    toks = tokenize(title)
    if not toks:
        return {"trend_overlap_count": 0, "trend_overlap_ratio": 0.0, "trend_cosine_sim": 0.0}

    # 1) overlap
    hw = set(hotwords)
    overlap = sum(1 for t in toks if t in hw)
    ratio = overlap / max(1, len(toks))

    # 2) cosine (BoW vs trending corpus)
    cosine = 0.0
    if trend_titles_for_bow is not None and len(trend_titles_for_bow) > 0:
        cv = CountVectorizer(tokenizer=tokenize)
        bow_corpus = trend_titles_for_bow + [title]
        X = cv.fit_transform(bow_corpus)
        sim = cosine_similarity(X[-1], X[:-1]).ravel()
        cosine = float(np.mean(sim))  # ã‚¿ã‚¤ãƒˆãƒ«ã¨æ€¥ä¸Šæ˜‡é›†åˆã®å¹³å‡é¡ä¼¼åº¦

    return {
        "trend_overlap_count": int(overlap),
        "trend_overlap_ratio": float(ratio),
        "trend_cosine_sim": float(cosine)
    }

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--trending_csvs", nargs="+", required=True)
    ap.add_argument("--title", type=str, default=None)
    ap.add_argument("--topk", type=int, default=500)
    ap.add_argument("--out_vocab", default="trend_vocab.json")
    args = ap.parse_args()

    hotwords, titles = build_trend_vocab_from_csvs(args.trending_csvs, top_k=args.topk)
    save_trend_vocab_json(hotwords, args.out_vocab)
    print(f"âœ… Saved vocab: {args.out_vocab} (hotwords={len(hotwords)})")

    if args.title:
        feats = title_trend_features(args.title, hotwords, titles)
        print("ğŸ” Features for title:", args.title)
        print(feats)

if __name__ == "__main__":
    main()
