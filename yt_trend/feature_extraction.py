# âœ… feature_extraction.pyï¼ˆå®Œå…¨ç‰ˆï¼š307æ¬¡å…ƒå¯¾å¿œï¼‰
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from PIL import Image
import requests
from io import BytesIO
from tqdm import tqdm
import joblib

# ğŸ“¥ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df = pd.read_excel("youtube_dataset.xlsx")

# ğŸ”¤ ã‚¿ã‚¤ãƒˆãƒ«TF-IDFï¼ˆ300æ¬¡å…ƒï¼‰
vectorizer = TfidfVectorizer(max_features=300)
tfidf_matrix = vectorizer.fit_transform(df["title"].fillna(""))
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f"tfidf_{t}" for t in vectorizer.get_feature_names_out()])
tfidf_df.index = df.index

# ğŸ“Š ã‚«ãƒ†ã‚´ãƒªå¤‰æ›
df["categoryId"] = pd.to_numeric(df["categoryId"], errors='coerce').fillna(-1).astype(int)

# ğŸ¨ ã‚µãƒ ãƒã‚¤ãƒ«æ˜åº¦
print("ğŸ¨ ã‚µãƒ ãƒã‚¤ãƒ«æ˜åº¦æŠ½å‡ºä¸­...")
def extract_thumbnail_brightness(url):
    try:
        img = Image.open(BytesIO(requests.get(url, timeout=5).content)).convert("L").resize((64, 64))
        return np.mean(np.array(img))
    except:
        return np.nan

df["thumbnail_brightness"] = [extract_thumbnail_brightness(url) for url in tqdm(df["thumbnail"].fillna(""))]
df["thumbnail_brightness"] = df["thumbnail_brightness"].fillna(df["thumbnail_brightness"].mean())

# âœ¨ æ‹¡å¼µç‰¹å¾´é‡
df["title_length"] = df["title"].fillna("").str.len()
df["description_length"] = df["description"].fillna("").str.len()
df["has_shorts"] = df["title"].str.contains("shorts", case=False, na=False).astype(int)

# ğŸ§  ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚³ãƒ¡ãƒ³ãƒˆãƒ¯ãƒ¼ãƒ‰ã‚¹ã‚³ã‚¢
df["trend_score"] = df.apply(lambda row: sum(kw in str(row["title"]) + str(row["description"]) for kw in ["shorts", "tiktok", "ç ´ç”£", "å…±æ„Ÿæ€§ç¾æ¥", "ç‚ä¸Š"]), axis=1)
with open("comment_keywords.txt", encoding="utf-8") as f:
    interest_keywords = [line.strip() for line in f.readlines()]
df["interest_score"] = df.apply(lambda row: sum(kw in str(row["title"]) + str(row["description"]) for kw in interest_keywords), axis=1)

# âœ… ç‰¹å¾´é‡ã‚»ãƒƒãƒˆ
feature_df = pd.concat([
    df[["categoryId", "thumbnail_brightness", "title_length", "description_length", "has_shorts", "trend_score", "interest_score"]],
    tfidf_df
], axis=1)

# ğŸ”¢ ç›®çš„å¤‰æ•°
df["log_view"] = np.log1p(df["viewCount"])
X = feature_df
y = df["log_view"]

# ğŸ’¾ ä¿å­˜
X.to_pickle("X.pkl")
y.to_pickle("y.pkl")
joblib.dump(vectorizer, "vectorizer.pkl")

print("âœ… ç‰¹å¾´é‡è¨­è¨ˆ å®Œäº†ï¼ï¼ˆ307æ¬¡å…ƒï¼‰")
