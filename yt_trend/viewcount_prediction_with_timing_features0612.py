import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from janome.tokenizer import Tokenizer
from isodate import parse_duration

# ğŸ“¥ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df = pd.read_excel("youtube_dataset.xlsx")

# ğŸ§  Shortsåˆ¤å®šï¼ˆdurationã‹ã‚‰60ç§’ä»¥ä¸‹ã‚’Shortsã¨ã™ã‚‹ï¼‰
df["duration_seconds"] = df["duration"].apply(lambda x: parse_duration(x).total_seconds())
df["is_shorts"] = df["duration_seconds"] <= 60

# ğŸ¯ é€šå¸¸å‹•ç”»ï¼ˆShortsã§ãªã„ï¼‰ã ã‘æŠ½å‡º
df = df[df["is_shorts"] == False].copy()

# ğŸ”§ æ¬ æè£œå®Œã¨å‹å¤‰æ›
df["title"] = df["title"].fillna("")
df["description"] = df["description"].fillna("")
df["categoryId"] = pd.to_numeric(df["categoryId"], errors="coerce").fillna(-1).astype(int)
df["viewCount"] = pd.to_numeric(df["viewCount"], errors="coerce").fillna(0)
df["publishedAt"] = pd.to_datetime(df["publishedAt"], errors="coerce")

# ğŸ•’ æŠ•ç¨¿ã‚¿ã‚¤ãƒŸãƒ³ã‚°ç‰¹å¾´é‡
df["weekday"] = df["publishedAt"].dt.weekday
df["hour"] = df["publishedAt"].dt.hour
df["is_weekend"] = df["weekday"].apply(lambda x: 1 if x >= 5 else 0)
df["day"] = df["publishedAt"].dt.day
df["is_month_start"] = df["day"] <= 3
df["is_month_end"] = df["day"] >= 28
df.drop(columns=["day"], inplace=True)

# ğŸ”¤ Janomeã§TF-IDFï¼ˆ100æ¬¡å…ƒï¼‰
tokenizer = Tokenizer()
def tokenize_japanese(text):
    return [token.base_form for token in tokenizer.tokenize(text)
            if token.part_of_speech.split(',')[0] in ['åè©', 'å‹•è©', 'å½¢å®¹è©']]

vectorizer = TfidfVectorizer(tokenizer=tokenize_japanese, token_pattern=None, max_features=100)
tfidf_matrix = vectorizer.fit_transform(df["title"])
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f"tfidf_{w}" for w in vectorizer.get_feature_names_out()])

# ğŸ¯ ç›®çš„å¤‰æ•°ï¼ˆlogã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
y = np.log1p(df["viewCount"])

# ğŸ“Š ç‰¹å¾´é‡å®šç¾©
X_base = pd.concat([df[["categoryId"]].reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)
timing_cols = ["weekday", "hour", "is_weekend", "is_month_start", "is_month_end"]
X_ext = pd.concat([df[["categoryId"] + timing_cols].reset_index(drop=True), tfidf_df.reset_index(drop=True)], axis=1)

# ğŸš€ å­¦ç¿’ãƒ»è©•ä¾¡é–¢æ•°
def evaluate_model(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    return rmse

# ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«ç²¾åº¦æ¯”è¼ƒ
rmse_base = evaluate_model(X_base, y)
rmse_ext = evaluate_model(X_ext, y)

# ğŸ“ çµæœå‡ºåŠ›
print(f"ğŸ“‰ é€šå¸¸å‹•ç”»ã®ã¿ã§ã®ãƒ¢ãƒ‡ãƒ«ç²¾åº¦æ¯”è¼ƒï¼ˆRMSE, logã‚¹ã‚±ãƒ¼ãƒ«ï¼‰")
print(f"- TF-IDF + categoryId ãƒ¢ãƒ‡ãƒ«ï¼š{rmse_base:.4f}")
print(f"- + æŠ•ç¨¿ã‚¿ã‚¤ãƒŸãƒ³ã‚°æ‹¡å¼µãƒ¢ãƒ‡ãƒ«ï¼š{rmse_ext:.4f}")
