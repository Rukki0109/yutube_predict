from googleapiclient.discovery import build
import pandas as pd
from tqdm import tqdm
import time

# âœ… APIã‚­ãƒ¼è¨­å®šï¼ˆè‡ªåˆ†ã®ã‚­ãƒ¼ã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼‰
API_KEY = "AIzaSyApavwxqaBLkNyK65iHdgmUf9eX5CsYrmI"
youtube = build("youtube", "v3", developerKey=API_KEY)

# âœ… å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«IDï¼ˆã‚¹ãƒ†ã‚´ãƒ­ãƒ‘ãƒ³ãƒãƒ£ãƒ¼ã‚ºï¼‰
CHANNEL_ID = "UCusnpkgavQhPV_8e_zEh_jw"

# âœ… å‹•ç”»IDå–å¾—
def get_video_ids(channel_id, max_results=1000):
    video_ids = []
    next_page_token = None
    print("ğŸ¬ å‹•ç”»IDå–å¾—ä¸­...")
    while len(video_ids) < max_results:
        req = youtube.search().list(
            part="id",
            channelId=channel_id,
            maxResults=50,
            type='video',
            order="date",
            pageToken=next_page_token
        )
        res = req.execute()
        for item in res["items"]:
            if item["id"]["kind"] == "youtube#video":
                video_ids.append(item["id"]["videoId"])
        next_page_token = res.get("nextPageToken")
        if not next_page_token:
            break
        time.sleep(0.1)
    return video_ids[:max_results]

# âœ… å‹•ç”»è©³ç´°å–å¾—
def get_video_details(video_ids):
    all_data = []
    print("ğŸ“¦ å‹•ç”»æƒ…å ±å–å¾—ä¸­...")
    for i in tqdm(range(0, len(video_ids), 50)):
        batch = video_ids[i:i+50]
        res = youtube.videos().list(
            part="snippet,statistics,contentDetails",
            id=",".join(batch)
        ).execute()
        for item in res["items"]:
            snippet = item.get("snippet", {})
            stats = item.get("statistics", {})
            content = item.get("contentDetails", {})
            all_data.append({
                "videoId": item["id"],
                "title": snippet.get("title"),
                "description": snippet.get("description"),
                "publishedAt": snippet.get("publishedAt"),
                "categoryId": snippet.get("categoryId"),
                "tags": snippet.get("tags", []),
                "thumbnail": snippet.get("thumbnails", {}).get("high", {}).get("url"),
                "viewCount": int(stats.get("viewCount", 0)),
                "likeCount": int(stats.get("likeCount", 0)) if "likeCount" in stats else None,
                "commentCount": int(stats.get("commentCount", 0)) if "commentCount" in stats else None,
                "duration": content.get("duration")
            })
        time.sleep(0.1)
    return pd.DataFrame(all_data)

# âœ… å®Ÿè¡Œ
video_ids = get_video_ids(CHANNEL_ID, max_results=1000)
df = get_video_details(video_ids)

# âœ… ä¿å­˜ï¼ˆå¿…è¦ãªã‚‰ï¼‰
df.to_excel("youtube_dataset.xlsx", index=False)
print("âœ… å®Œäº†ï¼å‹•ç”»æ•°:", len(df))
